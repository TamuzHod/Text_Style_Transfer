{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/fasttext-wikinews/wiki-news-300d-1M.vec\n",
      "./data/preprocessed/train_df.csv\n",
      "./data/preprocessed/bibles_suffled.csv\n",
      "./data/preprocessed/newbible.tsv\n",
      "./data/preprocessed/oldbible.tsv\n",
      "./data/preprocessed/test_df.csv\n",
      "./data/preprocessed/val_df.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import codecs\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('./data'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "        \n",
    "import torch as tf\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import math, copy, time\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "CUDA = tf.cuda.is_available()\n",
    "DEVICE=tf.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "    \"\"\"\n",
    "    A standard Encoder-Decoder architecture. Base for this and many \n",
    "    other models.\n",
    "    \"\"\"\n",
    "    def __init__(self, encoder, decoder, src_embed, trg_embed, generator):\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.src_embed = src_embed\n",
    "        self.trg_embed = trg_embed\n",
    "        self.generator = generator\n",
    "        \n",
    "    def forward(self, src, trg, src_mask, trg_mask, src_lengths, trg_lengths):\n",
    "        \"\"\"Take in and process masked src and target sequences.\"\"\"\n",
    "        encoder_hidden, encoder_final = self.encode(src, src_mask, src_lengths)\n",
    "        return self.decode(encoder_hidden, encoder_final, src_mask, trg, trg_mask)\n",
    "    \n",
    "    def encode(self, src, src_mask, src_lengths):\n",
    "        return self.encoder(self.src_embed(src), src_mask, src_lengths)\n",
    "    \n",
    "    def decode(self, encoder_hidden, encoder_final, src_mask, trg, trg_mask,\n",
    "               decoder_hidden=None):\n",
    "        return self.decoder(self.trg_embed(trg), encoder_hidden, encoder_final,\n",
    "                            src_mask, trg_mask, hidden=decoder_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \"\"\"Define standard linear + softmax generation step.\"\"\"\n",
    "    def __init__(self, hidden_size, vocab_size):\n",
    "        super(Generator, self).__init__()\n",
    "        self.proj = nn.Linear(hidden_size, vocab_size, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.log_softmax(self.proj(x), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"\"\"Encodes a sequence of word embeddings\"\"\"\n",
    "    def __init__(self, input_size, hidden_size, num_layers=1, dropout=0.):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.rnn = nn.GRU(input_size, hidden_size, num_layers, \n",
    "                          batch_first=True, bidirectional=True, dropout=dropout)\n",
    "        \n",
    "    def forward(self, x, mask, lengths):\n",
    "        \"\"\"\n",
    "        Applies a bidirectional GRU to sequence of embeddings x.\n",
    "        The input mini-batch x needs to be sorted by length.\n",
    "        x should have dimensions [batch, time, dim].\n",
    "        \"\"\"\n",
    "        packed = pack_padded_sequence(x, lengths, batch_first=True)\n",
    "        output, final = self.rnn(packed)\n",
    "        output, _ = pad_packed_sequence(output, batch_first=True)\n",
    "\n",
    "        # we need to manually concatenate the final states for both directions\n",
    "        fwd_final = final[0:final.size(0):2]\n",
    "        bwd_final = final[1:final.size(0):2]\n",
    "        final = torch.cat([fwd_final, bwd_final], dim=2)  # [num_layers, batch, 2*dim]\n",
    "\n",
    "        return output, final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \"\"\"A conditional RNN decoder with attention.\"\"\"\n",
    "    \n",
    "    def __init__(self, emb_size, hidden_size, attention, num_layers=1, dropout=0.5,\n",
    "                 bridge=True):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.attention = attention\n",
    "        self.dropout = dropout\n",
    "                 \n",
    "        self.rnn = nn.GRU(emb_size + 2*hidden_size, hidden_size, num_layers,\n",
    "                          batch_first=True, dropout=dropout)\n",
    "                 \n",
    "        # to initialize from the final encoder state\n",
    "        self.bridge = nn.Linear(2*hidden_size, hidden_size, bias=True) if bridge else None\n",
    "\n",
    "        self.dropout_layer = nn.Dropout(p=dropout)\n",
    "        self.pre_output_layer = nn.Linear(hidden_size + 2*hidden_size + emb_size,\n",
    "                                          hidden_size, bias=False)\n",
    "        \n",
    "    def forward_step(self, prev_embed, encoder_hidden, src_mask, proj_key, hidden):\n",
    "        \"\"\"Perform a single decoder step (1 word)\"\"\"\n",
    "\n",
    "        # compute context vector using attention mechanism\n",
    "        query = hidden[-1].unsqueeze(1)  # [#layers, B, D] -> [B, 1, D]\n",
    "        context, attn_probs = self.attention(\n",
    "            query=query, proj_key=proj_key,\n",
    "            value=encoder_hidden, mask=src_mask)\n",
    "\n",
    "        # update rnn hidden state\n",
    "        rnn_input = torch.cat([prev_embed, context], dim=2)\n",
    "        output, hidden = self.rnn(rnn_input, hidden)\n",
    "        \n",
    "        pre_output = torch.cat([prev_embed, output, context], dim=2)\n",
    "        pre_output = self.dropout_layer(pre_output)\n",
    "        pre_output = self.pre_output_layer(pre_output)\n",
    "\n",
    "        return output, hidden, pre_output\n",
    "    \n",
    "    def forward(self, trg_embed, encoder_hidden, encoder_final, \n",
    "                src_mask, trg_mask, hidden=None, max_len=None):\n",
    "        \"\"\"Unroll the decoder one step at a time.\"\"\"\n",
    "                                         \n",
    "        # the maximum number of steps to unroll the RNN\n",
    "        if max_len is None:\n",
    "            max_len = trg_mask.size(-1)\n",
    "\n",
    "        # initialize decoder hidden state\n",
    "        if hidden is None:\n",
    "            hidden = self.init_hidden(encoder_final)\n",
    "        \n",
    "        # pre-compute projected encoder hidden states\n",
    "        # (the \"keys\" for the attention mechanism)\n",
    "        # this is only done for efficiency\n",
    "        proj_key = self.attention.key_layer(encoder_hidden)\n",
    "        \n",
    "        # here we store all intermediate hidden states and pre-output vectors\n",
    "        decoder_states = []\n",
    "        pre_output_vectors = []\n",
    "        \n",
    "        # unroll the decoder RNN for max_len steps\n",
    "        for i in range(max_len):\n",
    "            prev_embed = trg_embed[:, i].unsqueeze(1)\n",
    "            output, hidden, pre_output = self.forward_step(\n",
    "              prev_embed, encoder_hidden, src_mask, proj_key, hidden)\n",
    "            decoder_states.append(output)\n",
    "            pre_output_vectors.append(pre_output)\n",
    "\n",
    "        decoder_states = torch.cat(decoder_states, dim=1)\n",
    "        pre_output_vectors = torch.cat(pre_output_vectors, dim=1)\n",
    "        return decoder_states, hidden, pre_output_vectors  # [B, N, D]\n",
    "\n",
    "    def init_hidden(self, encoder_final):\n",
    "        \"\"\"Returns the initial decoder state,\n",
    "        conditioned on the final encoder state.\"\"\"\n",
    "\n",
    "        if encoder_final is None:\n",
    "            return None  # start with zeros\n",
    "\n",
    "        return torch.tanh(self.bridge(encoder_final))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(nn.Module):\n",
    "    \"\"\"Implements Bahdanau (MLP) attention\"\"\"\n",
    "    \n",
    "    def __init__(self, hidden_size, key_size=None, query_size=None):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        \n",
    "        # We assume a bi-directional encoder so key_size is 2*hidden_size\n",
    "        key_size = 2 * hidden_size if key_size is None else key_size\n",
    "        query_size = hidden_size if query_size is None else query_size\n",
    "\n",
    "        self.key_layer = nn.Linear(key_size, hidden_size, bias=False)\n",
    "        self.query_layer = nn.Linear(query_size, hidden_size, bias=False)\n",
    "        self.energy_layer = nn.Linear(hidden_size, 1, bias=False)\n",
    "        \n",
    "        # to store attention scores\n",
    "        self.alphas = None\n",
    "        \n",
    "    def forward(self, query=None, proj_key=None, value=None, mask=None):\n",
    "        assert mask is not None, \"mask is required\"\n",
    "\n",
    "        # We first project the query (the decoder state).\n",
    "        # The projected keys (the encoder states) were already pre-computated.\n",
    "        query = self.query_layer(query)\n",
    "        \n",
    "        # Calculate scores.\n",
    "        scores = self.energy_layer(torch.tanh(query + proj_key))\n",
    "        scores = scores.squeeze(2).unsqueeze(1)\n",
    "        \n",
    "        # Mask out invalid positions.\n",
    "        # The mask marks valid positions so we invert it using `mask & 0`.\n",
    "        scores.data.masked_fill_(mask == 0, -float('inf'))\n",
    "        \n",
    "        # Turn scores to probabilities.\n",
    "        alphas = F.softmax(scores, dim=-1)\n",
    "        self.alphas = alphas        \n",
    "        \n",
    "        # The context vector is the weighted sum of the values.\n",
    "        context = torch.bmm(alphas, value)\n",
    "        \n",
    "        # context shape: [B, 1, 2D], alphas shape: [B, 1, M]\n",
    "        return context, alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(src_vocab, tgt_vocab, emb_size=256, hidden_size=512, num_layers=1, dropout=0.1):\n",
    "    \"Helper: Construct a model from hyperparameters.\"\n",
    "\n",
    "    attention = BahdanauAttention(hidden_size)\n",
    "\n",
    "    model = EncoderDecoder(\n",
    "        Encoder(emb_size, hidden_size, num_layers=num_layers, dropout=dropout),\n",
    "        Decoder(emb_size, hidden_size, attention, num_layers=num_layers, dropout=dropout),\n",
    "        nn.Embedding(src_vocab, emb_size),\n",
    "        nn.Embedding(tgt_vocab, emb_size),\n",
    "        Generator(hidden_size, tgt_vocab))\n",
    "\n",
    "    return model.cuda() if USE_CUDA else model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Batch:\n",
    "    \"\"\"Object for holding a batch of data with mask during training.\n",
    "    Input is a batch from a torch text iterator.\n",
    "    \"\"\"\n",
    "    def __init__(self, src, trg, pad_index=0):\n",
    "        \n",
    "        src, src_lengths = src\n",
    "        \n",
    "        self.src = src\n",
    "        self.src_lengths = src_lengths\n",
    "        self.src_mask = (src != pad_index).unsqueeze(-2)\n",
    "        self.nseqs = src.size(0)\n",
    "        \n",
    "        self.trg = None\n",
    "        self.trg_y = None\n",
    "        self.trg_mask = None\n",
    "        self.trg_lengths = None\n",
    "        self.ntokens = None\n",
    "\n",
    "        if trg is not None:\n",
    "            trg, trg_lengths = trg\n",
    "            self.trg = trg[:, :-1]\n",
    "            self.trg_lengths = trg_lengths\n",
    "            self.trg_y = trg[:, 1:]\n",
    "            self.trg_mask = (self.trg_y != pad_index)\n",
    "            self.ntokens = (self.trg_y != pad_index).data.sum().item()\n",
    "        \n",
    "        if USE_CUDA:\n",
    "            self.src = self.src.cuda()\n",
    "            self.src_mask = self.src_mask.cuda()\n",
    "\n",
    "            if trg is not None:\n",
    "                self.trg = self.trg.cuda()\n",
    "                self.trg_y = self.trg_y.cuda()\n",
    "                self.trg_mask = self.trg_mask.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(data_iter, model, loss_compute, print_every=50):\n",
    "    \"\"\"Standard Training and Logging Function\"\"\"\n",
    "\n",
    "    start = time.time()\n",
    "    total_tokens = 0\n",
    "    total_loss = 0\n",
    "    print_tokens = 0\n",
    "\n",
    "    for i, batch in enumerate(data_iter, 1):\n",
    "        out, _, pre_output = model.forward(batch.src, batch.trg,\n",
    "                                           batch.src_mask, batch.trg_mask,\n",
    "                                           batch.src_lengths, batch.trg_lengths)\n",
    "        loss = loss_compute(pre_output, batch.trg_y, batch.nseqs)\n",
    "        total_loss += loss\n",
    "        total_tokens += batch.ntokens\n",
    "        print_tokens += batch.ntokens\n",
    "        if model.training and i % print_every == 0:\n",
    "            elapsed = time.time() - start\n",
    "            print(\"Epoch Step: %d Loss: %f Tokens per Sec: %f\" %\n",
    "                    (i, loss / batch.nseqs, print_tokens / elapsed))\n",
    "            start = time.time()\n",
    "            print_tokens = 0\n",
    "\n",
    "    return math.exp(total_loss / float(total_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_examples(example_iter, model, n=2, max_len=100, \n",
    "                   sos_index=1, \n",
    "                   src_eos_index=None, \n",
    "                   trg_eos_index=None, \n",
    "                   src_vocab=None, trg_vocab=None):\n",
    "    \"\"\"Prints N examples. Assumes batch size of 1.\"\"\"\n",
    "\n",
    "    model.eval()\n",
    "    count = 0\n",
    "    print()\n",
    "    \n",
    "    if src_vocab is not None and trg_vocab is not None:\n",
    "        src_eos_index = src_vocab.stoi[EOS_TOKEN]\n",
    "        trg_sos_index = trg_vocab.stoi[SOS_TOKEN]\n",
    "        trg_eos_index = trg_vocab.stoi[EOS_TOKEN]\n",
    "    else:\n",
    "        src_eos_index = None\n",
    "        trg_sos_index = 1\n",
    "        trg_eos_index = None\n",
    "        \n",
    "    for i, batch in enumerate(example_iter):\n",
    "        if(i % 2 == 0):\n",
    "            continue\n",
    "        src = batch.src.cpu().numpy()[0, :]\n",
    "        trg = batch.trg_y.cpu().numpy()[0, :]\n",
    "\n",
    "        # remove </s> (if it is there)\n",
    "        src = src[:-1] if src[-1] == src_eos_index else src\n",
    "        trg = trg[:-1] if trg[-1] == trg_eos_index else trg      \n",
    "      \n",
    "        result, _ = greedy_decode(\n",
    "          model, batch.src, batch.src_mask, batch.src_lengths,\n",
    "          max_len=max_len, sos_index=trg_sos_index, eos_index=trg_eos_index)\n",
    "        print(\"Example #%d\" % (count+1))\n",
    "        print(\"Src : \", \" \".join(lookup_words(src, vocab=src_vocab)))\n",
    "        print(\"Trg : \", \" \".join(lookup_words(trg, vocab=trg_vocab)))\n",
    "        print(\"Pred: \", \" \".join(lookup_words(result, vocab=trg_vocab)))\n",
    "        print()\n",
    "        count += 1\n",
    "        if count == n:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_gen(num_words=11, batch_size=16, num_batches=100, length=10, pad_index=0, sos_index=1):\n",
    "    \"\"\"Generate random data for a src-tgt copy task.\"\"\"\n",
    "    for i in range(num_batches):\n",
    "        data = torch.from_numpy(\n",
    "          np.random.randint(1, num_words, size=(batch_size, length)))\n",
    "        data[:, 0] = sos_index\n",
    "        data = data.cuda() if USE_CUDA else data\n",
    "        src = data[:, 1:]\n",
    "        trg = data\n",
    "        src_lengths = [length-1] * batch_size\n",
    "        trg_lengths = [length] * batch_size\n",
    "        yield Batch((src, src_lengths), (trg, trg_lengths), pad_index=pad_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLossCompute:\n",
    "    \"\"\"A simple loss compute and train function.\"\"\"\n",
    "\n",
    "    def __init__(self, generator, criterion, opt=None):\n",
    "        self.generator = generator\n",
    "        self.criterion = criterion\n",
    "        self.opt = opt\n",
    "\n",
    "    def __call__(self, x, y, norm):\n",
    "        x = self.generator(x)\n",
    "        loss = self.criterion(x.contiguous().view(-1, x.size(-1)),\n",
    "                              y.contiguous().view(-1))\n",
    "        loss = loss / norm\n",
    "\n",
    "        if self.opt is not None:\n",
    "            loss.backward()          \n",
    "            self.opt.step()\n",
    "            self.opt.zero_grad()\n",
    "\n",
    "        return loss.data.item() * norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_decode(model, src, src_mask, src_lengths, max_len=100, sos_index=1, eos_index=None):\n",
    "    \"\"\"Greedily decode a sentence.\"\"\"\n",
    "\n",
    "    with torch.no_grad():\n",
    "        encoder_hidden, encoder_final = model.encode(src, src_mask, src_lengths)\n",
    "        prev_y = torch.ones(1, 1).fill_(sos_index).type_as(src)\n",
    "        trg_mask = torch.ones_like(prev_y)\n",
    "\n",
    "    output = []\n",
    "    attention_scores = []\n",
    "    hidden = None\n",
    "\n",
    "    for i in range(max_len):\n",
    "        with torch.no_grad():\n",
    "            out, hidden, pre_output = model.decode(\n",
    "              encoder_hidden, encoder_final, src_mask,\n",
    "              prev_y, trg_mask, hidden)\n",
    "\n",
    "            # we predict from the pre-output layer, which is\n",
    "            # a combination of Decoder state, prev emb, and context\n",
    "            prob = model.generator(pre_output[:, -1])\n",
    "\n",
    "        _, next_word = torch.max(prob, dim=1)\n",
    "        next_word = next_word.data.item()\n",
    "        output.append(next_word)\n",
    "        prev_y = torch.ones(1, 1).type_as(src).fill_(next_word)\n",
    "        attention_scores.append(model.decoder.attention.alphas.cpu().numpy())\n",
    "    \n",
    "    output = np.array(output)\n",
    "        \n",
    "    # cut off everything starting from </s> \n",
    "    # (only when eos_index provided)\n",
    "    if eos_index is not None:\n",
    "        first_eos = np.where(output==eos_index)[0]\n",
    "        if len(first_eos) > 0:\n",
    "            output = output[:first_eos[0]]      \n",
    "    \n",
    "    return output, np.concatenate(attention_scores, axis=1)\n",
    "  \n",
    "\n",
    "def lookup_words(x, vocab=None):\n",
    "    if vocab is not None:\n",
    "        x = [vocab.itos[i] for i in x]\n",
    "\n",
    "    return [str(t) for t in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_perplexity(perplexities):\n",
    "    \"\"\"plot perplexities\"\"\"\n",
    "    plt.title(\"Perplexity per Epoch\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Perplexity\")\n",
    "    plt.plot(perplexities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext import data, datasets\n",
    "import en_core_web_sm\n",
    "en = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "spacy_en = spacy.load('en_core_web_sm')\n",
    "\n",
    "def tokenize_en(text):\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]\n",
    "\n",
    "UNK_TOKEN = \"<unk>\"\n",
    "PAD_TOKEN = \"<pad>\"    \n",
    "SOS_TOKEN = \"<s>\"\n",
    "EOS_TOKEN = \"</s>\"\n",
    "LOWER = True\n",
    "\n",
    "# we include lengths to provide to the RNNs\n",
    "SRC = data.Field(tokenize=tokenize_en, \n",
    "                 batch_first=True, lower=LOWER, include_lengths=True,\n",
    "                 unk_token=UNK_TOKEN, pad_token=PAD_TOKEN, init_token=None, eos_token=EOS_TOKEN)\n",
    "\n",
    "TRG = data.Field(tokenize=tokenize_en, \n",
    "                 batch_first=True, lower=LOWER, include_lengths=True,\n",
    "                 unk_token=UNK_TOKEN, pad_token=PAD_TOKEN, init_token=SOS_TOKEN, eos_token=EOS_TOKEN)\n",
    "\n",
    "MAX_LEN_SRC = 50 \n",
    "MAX_LEN_TRG = 50  \n",
    "\n",
    "fields = [\n",
    "    ('ID', None), # we dont need this, so no processing\n",
    "    ('src', SRC), # process it as label\n",
    "    ('trg', TRG) # process it as text\n",
    "]\n",
    "\n",
    "\n",
    "train_data, valid_data, test_data = data.TabularDataset.splits(path='./data/preprocessed/',train='train_df.csv',\n",
    "                                    validation='val_df.csv', test='test_df.csv', format='csv',\n",
    "                                    fields=fields,\n",
    "                                    filter_pred=lambda x: len(vars(x)['src']) <= MAX_LEN_SRC \n",
    "                                    and len(vars(x)['trg']) <= MAX_LEN_TRG)\n",
    "\n",
    "MIN_FREQ = 5  # NOTE: we limit the vocabulary to frequent words for speed\n",
    "\n",
    "SRC.build_vocab(train_data.src, min_freq=MIN_FREQ)\n",
    "TRG.build_vocab(train_data.trg, min_freq=MIN_FREQ)\n",
    "PAD_INDEX = TRG.vocab.stoi[PAD_TOKEN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data set sizes (number of sentence pairs):\n",
      "train 21149\n",
      "valid 6064\n",
      "test 3036 \n",
      "\n",
      "First training example:\n",
      "src: then from before him sent is the extremity of the hand and the writing is noted down\n",
      "trg: then was the part of the hand sent from before him and this writing was inscribed \n",
      "\n",
      "Most common words (src):\n",
      "       and      38562\n",
      "       the      36059\n",
      "        of      24000\n",
      "        to      14279\n",
      "        in       9511\n",
      "        is       8165\n",
      "        he       6509\n",
      "       for       6007\n",
      "       his       5481\n",
      "      hath       5432 \n",
      "\n",
      "Most common words (trg):\n",
      "       the      37554\n",
      "       and      23022\n",
      "        of      22092\n",
      "        to      13885\n",
      "       you      10015\n",
      "        in       8335\n",
      "        he       6941\n",
      "       for       5953\n",
      "      that       5573\n",
      "       his       5361 \n",
      "\n",
      "First 10 words (src):\n",
      "00 <unk>\n",
      "01 <pad>\n",
      "02 </s>\n",
      "03 and\n",
      "04 the\n",
      "05 of\n",
      "06 to\n",
      "07 in\n",
      "08 is\n",
      "09 he \n",
      "\n",
      "First 10 words (trg):\n",
      "00 <unk>\n",
      "01 <pad>\n",
      "02 <s>\n",
      "03 </s>\n",
      "04 the\n",
      "05 and\n",
      "06 of\n",
      "07 to\n",
      "08 you\n",
      "09 in \n",
      "\n",
      "Number of text words (types): 4306\n",
      "Number of title words (types): 4351 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_data_info(train_data, valid_data, test_data, src_field, trg_field):\n",
    "    \"\"\" This prints some useful stuff about our data sets. \"\"\"\n",
    "\n",
    "    print(\"Data set sizes (number of sentence pairs):\")\n",
    "    print('train', len(train_data))\n",
    "    print('valid', len(valid_data))\n",
    "    print('test', len(test_data), \"\\n\")\n",
    "\n",
    "    print(\"First training example:\")\n",
    "    print(\"src:\", \" \".join(vars(train_data[0])['src']))\n",
    "    print(\"trg:\", \" \".join(vars(train_data[0])['trg']), \"\\n\")\n",
    "    \n",
    "    print(\"Most common words (src):\")\n",
    "    print(\"\\n\".join([\"%10s %10d\" % x for x in src_field.vocab.freqs.most_common(10)]), \"\\n\")\n",
    "    print(\"Most common words (trg):\")\n",
    "    print(\"\\n\".join([\"%10s %10d\" % x for x in trg_field.vocab.freqs.most_common(10)]), \"\\n\")\n",
    "\n",
    "    print(\"First 10 words (src):\")\n",
    "    print(\"\\n\".join(\n",
    "        '%02d %s' % (i, t) for i, t in enumerate(src_field.vocab.itos[:10])), \"\\n\")\n",
    "    print(\"First 10 words (trg):\")\n",
    "    print(\"\\n\".join(\n",
    "        '%02d %s' % (i, t) for i, t in enumerate(trg_field.vocab.itos[:10])), \"\\n\")\n",
    "\n",
    "    print(\"Number of text words (types):\", len(src_field.vocab))\n",
    "    print(\"Number of title words (types):\", len(trg_field.vocab), \"\\n\")\n",
    "    \n",
    "    \n",
    "print_data_info(train_data, valid_data, test_data,   SRC, TRG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = data.BucketIterator(train_data, batch_size=batch_size, train=True, \n",
    "                                 sort_within_batch=True, \n",
    "                                 sort_key=lambda x: (len(x.src), len(x.trg)), repeat=False,\n",
    "                                 device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_iter = data.Iterator(valid_data, batch_size=1, train=False, sort=False, repeat=False, \n",
    "                           device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rebatch(pad_idx, batch):\n",
    "    \"\"\"Wrap torchtext batch into our own Batch class for pre-processing\"\"\"\n",
    "    return Batch(batch.src, batch.trg, pad_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, num_epochs=50, lr=0.0003, print_every=100):\n",
    "    \"\"\"Train a model on IWSLT\"\"\"\n",
    "    \n",
    "    if USE_CUDA:\n",
    "        model.cuda()\n",
    "\n",
    "    # optionally add label smoothing; see the Annotated Transformer\n",
    "    criterion = nn.NLLLoss(reduction=\"sum\", ignore_index=PAD_INDEX)\n",
    "    optim = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    dev_perplexities = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "      \n",
    "        print(\"Epoch\", epoch)\n",
    "        torch.save(model.state_dict(), 'model_epoch_' + str(epoch))\n",
    "\n",
    "        model.train()\n",
    "        train_perplexity = run_epoch((rebatch(PAD_INDEX, b) for b in train_iter), \n",
    "                                     model,\n",
    "                                     SimpleLossCompute(model.generator, criterion, optim),\n",
    "                                     print_every=print_every)\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            print_examples((rebatch(PAD_INDEX, x) for x in valid_iter), \n",
    "                           model, n=3, src_vocab=SRC.vocab, trg_vocab=TRG.vocab)        \n",
    "\n",
    "            dev_perplexity = run_epoch((rebatch(PAD_INDEX, b) for b in valid_iter), \n",
    "                                       model, \n",
    "                                       SimpleLossCompute(model.generator, criterion, None))\n",
    "            print(\"Validation perplexity: %f\" % dev_perplexity)\n",
    "            dev_perplexities.append(dev_perplexity)\n",
    "    torch.save(model.state_dict(), 'model_Final')\n",
    "\n",
    "    return dev_perplexities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Epoch Step: 100 Loss: 80.977150 Tokens per Sec: 7832.301123\n",
      "Epoch Step: 200 Loss: 175.746643 Tokens per Sec: 8195.350608\n",
      "Epoch Step: 300 Loss: 80.492233 Tokens per Sec: 8064.037693\n",
      "Epoch Step: 400 Loss: 152.455582 Tokens per Sec: 8074.161294\n",
      "Epoch Step: 500 Loss: 69.069016 Tokens per Sec: 7746.044165\n",
      "\n",
      "Example #1\n",
      "Src :  yea he putteth his life in his hand and smiteth the philistine and jehovah worketh great salvation for all israel thou hast seen and dost rejoice and why dost thou sin against innocent blood to put david to death for nought\n",
      "Trg :  for he put his life in his hand and struck the philistine and yahweh worked great victory for all israel you saw it and did rejoice why then will you sin against innocent blood to kill david without cause\n",
      "Pred:  he has his father in his hand and his hand and all the land and the land and all the land and all the land of israel and you have spoken to the land\n",
      "\n",
      "Example #2\n",
      "Src :  take therefore from him the talent and give to him having the ten talents\n",
      "Trg :  take away therefore the talent from him and give it to him who has the ten talents\n",
      "Pred:  then the king and the <unk> and the <unk> and the <unk>\n",
      "\n",
      "Example #3\n",
      "Src :  who not of blood nor of will of flesh nor of will of man but of god were begotten\n",
      "Trg :  who were born not of blood nor of the will of the flesh nor of the will of man but of god\n",
      "Pred:  who are not be of the <unk> of <unk> of god of god\n",
      "\n",
      "Validation perplexity: 61.483501\n",
      "Epoch 1\n",
      "Epoch Step: 100 Loss: 152.454117 Tokens per Sec: 7940.254352\n",
      "Epoch Step: 200 Loss: 73.834511 Tokens per Sec: 7653.134705\n",
      "Epoch Step: 300 Loss: 76.494919 Tokens per Sec: 7514.805720\n",
      "Epoch Step: 400 Loss: 62.192451 Tokens per Sec: 8439.653148\n",
      "Epoch Step: 500 Loss: 53.666046 Tokens per Sec: 7732.871642\n",
      "\n",
      "Example #1\n",
      "Src :  yea he putteth his life in his hand and smiteth the philistine and jehovah worketh great salvation for all israel thou hast seen and dost rejoice and why dost thou sin against innocent blood to put david to death for nought\n",
      "Trg :  for he put his life in his hand and struck the philistine and yahweh worked great victory for all israel you saw it and did rejoice why then will you sin against innocent blood to kill david without cause\n",
      "Pred:  he shall his brother in his hand and the <unk> and yahweh the great and yahweh had made for all israel and you have done and all that you have done and do you shall do you shall be given to him to him to him to him to him to death to him\n",
      "\n",
      "Example #2\n",
      "Src :  take therefore from him the talent and give to him having the ten talents\n",
      "Trg :  take away therefore the talent from him and give it to him who has the ten talents\n",
      "Pred:  therefore the hand of the house and the <unk> the <unk> of him\n",
      "\n",
      "Example #3\n",
      "Src :  who not of blood nor of will of flesh nor of will of man but of god were begotten\n",
      "Trg :  who were born not of blood nor of the will of the flesh nor of the will of man but of god\n",
      "Pred:  who doesn not eat of the flesh of the flesh of the flesh of the evil of god of god but god\n",
      "\n",
      "Validation perplexity: 28.813935\n",
      "Epoch 2\n",
      "Epoch Step: 100 Loss: 91.605339 Tokens per Sec: 6415.513508\n",
      "Epoch Step: 200 Loss: 58.381580 Tokens per Sec: 7979.689924\n",
      "Epoch Step: 300 Loss: 127.910072 Tokens per Sec: 7536.195747\n",
      "Epoch Step: 400 Loss: 53.267479 Tokens per Sec: 7541.670691\n",
      "Epoch Step: 500 Loss: 93.575706 Tokens per Sec: 7743.630808\n",
      "\n",
      "Example #1\n",
      "Src :  yea he putteth his life in his hand and smiteth the philistine and jehovah worketh great salvation for all israel thou hast seen and dost rejoice and why dost thou sin against innocent blood to put david to death for nought\n",
      "Trg :  for he put his life in his hand and struck the philistine and yahweh worked great victory for all israel you saw it and did rejoice why then will you sin against innocent blood to kill david without cause\n",
      "Pred:  he shall his soul in his hand and his hand and yahweh great great for all israel you have seen and you shall do good to give it to give to death to death to death\n",
      "\n",
      "Example #2\n",
      "Src :  take therefore from him the talent and give to him having the ten talents\n",
      "Trg :  take away therefore the talent from him and give it to him who has the ten talents\n",
      "Pred:  take him from him and the <unk> of him and gave him the other\n",
      "\n",
      "Example #3\n",
      "Src :  who not of blood nor of will of flesh nor of will of man but of god were begotten\n",
      "Trg :  who were born not of blood nor of the will of the flesh nor of the will of man but of god\n",
      "Pred:  who doesn not eat of blood nor of the flesh of the flesh of god but of god\n",
      "\n",
      "Validation perplexity: 17.245197\n",
      "Epoch 3\n",
      "Epoch Step: 100 Loss: 66.562729 Tokens per Sec: 7262.024248\n",
      "Epoch Step: 200 Loss: 46.775410 Tokens per Sec: 7257.011839\n",
      "Epoch Step: 300 Loss: 40.260929 Tokens per Sec: 7900.250467\n",
      "Epoch Step: 400 Loss: 78.529083 Tokens per Sec: 7506.879514\n",
      "Epoch Step: 500 Loss: 41.583881 Tokens per Sec: 7223.552251\n",
      "\n",
      "Example #1\n",
      "Src :  yea he putteth his life in his hand and smiteth the philistine and jehovah worketh great salvation for all israel thou hast seen and dost rejoice and why dost thou sin against innocent blood to put david to death for nought\n",
      "Trg :  for he put his life in his hand and struck the philistine and yahweh worked great victory for all israel you saw it and did rejoice why then will you sin against innocent blood to kill david without cause\n",
      "Pred:  he will his life in his hand and struck the philistine and yahweh made great salvation for all israel you have seen and you shall be forgiven and give you sin to give it to sin to death to death\n",
      "\n",
      "Example #2\n",
      "Src :  take therefore from him the talent and give to him having the ten talents\n",
      "Trg :  take away therefore the talent from him and give it to him who has the ten talents\n",
      "Pred:  take him from the <unk> and gave him him and the other side\n",
      "\n",
      "Example #3\n",
      "Src :  who not of blood nor of will of flesh nor of will of man but of god were begotten\n",
      "Trg :  who were born not of blood nor of the will of the flesh nor of the will of man but of god\n",
      "Pred:  who doesn not be blood nor any of the flesh of the flesh of the <unk> of the knowledge of god\n",
      "\n",
      "Validation perplexity: 13.348745\n",
      "Epoch 4\n",
      "Epoch Step: 100 Loss: 54.570415 Tokens per Sec: 7186.755701\n",
      "Epoch Step: 200 Loss: 86.659271 Tokens per Sec: 7618.831343\n",
      "Epoch Step: 300 Loss: 73.136101 Tokens per Sec: 8175.016521\n",
      "Epoch Step: 400 Loss: 54.161976 Tokens per Sec: 9251.981019\n",
      "Epoch Step: 500 Loss: 16.377817 Tokens per Sec: 7931.534540\n",
      "\n",
      "Example #1\n",
      "Src :  yea he putteth his life in his hand and smiteth the philistine and jehovah worketh great salvation for all israel thou hast seen and dost rejoice and why dost thou sin against innocent blood to put david to death for nought\n",
      "Trg :  for he put his life in his hand and struck the philistine and yahweh worked great victory for all israel you saw it and did rejoice why then will you sin against innocent blood to kill david without cause\n",
      "Pred:  he lifted up his life in his hand and struck the philistine and yahweh gave great salvation for all israel you have seen and do you see why should do sin against sin to death to death\n",
      "\n",
      "Example #2\n",
      "Src :  take therefore from him the talent and give to him having the ten talents\n",
      "Trg :  take away therefore the talent from him and give it to him who has the ten talents\n",
      "Pred:  take him from the baals and gave him <unk> and ten ten talents\n",
      "\n",
      "Example #3\n",
      "Src :  who not of blood nor of will of flesh nor of will of man but of god were begotten\n",
      "Trg :  who were born not of blood nor of the will of the flesh nor of the will of man but of god\n",
      "Pred:  who doesn not eat of blood nor of violence nor of the man of god but of god were glorified\n",
      "\n",
      "Validation perplexity: 11.266227\n",
      "Epoch 5\n",
      "Epoch Step: 100 Loss: 61.270840 Tokens per Sec: 7342.164095\n",
      "Epoch Step: 200 Loss: 54.798855 Tokens per Sec: 7437.862533\n",
      "Epoch Step: 300 Loss: 89.150101 Tokens per Sec: 7758.815260\n",
      "Epoch Step: 400 Loss: 62.860332 Tokens per Sec: 8577.601118\n",
      "Epoch Step: 500 Loss: 61.130325 Tokens per Sec: 7471.200987\n",
      "\n",
      "Example #1\n",
      "Src :  yea he putteth his life in his hand and smiteth the philistine and jehovah worketh great salvation for all israel thou hast seen and dost rejoice and why dost thou sin against innocent blood to put david to death for nought\n",
      "Trg :  for he put his life in his hand and struck the philistine and yahweh worked great victory for all israel you saw it and did rejoice why then will you sin against innocent blood to kill david without cause\n",
      "Pred:  he put his life in his hand and struck the philistine and yahweh gave great salvation for all israel you have seen and do you sin against sin if they should give to death to death\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example #2\n",
      "Src :  take therefore from him the talent and give to him having the ten talents\n",
      "Trg :  take away therefore the talent from him and give it to him who has the ten talents\n",
      "Pred:  take him from him the baals and gave him the ten talents\n",
      "\n",
      "Example #3\n",
      "Src :  who not of blood nor of will of flesh nor of will of man but of god were begotten\n",
      "Trg :  who were born not of blood nor of the will of the flesh nor of the will of man but of god\n",
      "Pred:  who doesn not be blood of the shadow of flesh neither of the flesh of the god of god and of god\n",
      "\n",
      "Validation perplexity: 11.710562\n",
      "Epoch 6\n",
      "Epoch Step: 100 Loss: 64.129440 Tokens per Sec: 7217.277562\n",
      "Epoch Step: 200 Loss: 37.448990 Tokens per Sec: 8522.761018\n",
      "Epoch Step: 300 Loss: 32.447514 Tokens per Sec: 9167.261786\n",
      "Epoch Step: 400 Loss: 56.850044 Tokens per Sec: 7081.775866\n",
      "Epoch Step: 500 Loss: 37.537956 Tokens per Sec: 8029.686449\n",
      "\n",
      "Example #1\n",
      "Src :  yea he putteth his life in his hand and smiteth the philistine and jehovah worketh great salvation for all israel thou hast seen and dost rejoice and why dost thou sin against innocent blood to put david to death for nought\n",
      "Trg :  for he put his life in his hand and struck the philistine and yahweh worked great victory for all israel you saw it and did rejoice why then will you sin against innocent blood to kill david without cause\n",
      "Pred:  he put his life in his hand and struck the philistine and yahweh gave great salvation for all israel you have seen and do you why do you sin against sin if put to death to death to death\n",
      "\n",
      "Example #2\n",
      "Src :  take therefore from him the talent and give to him having the ten talents\n",
      "Trg :  take away therefore the talent from him and give it to him who has the ten talents\n",
      "Pred:  take from him the one and gave him <unk> and ten ten talents\n",
      "\n",
      "Example #3\n",
      "Src :  who not of blood nor of will of flesh nor of will of man but of god were begotten\n",
      "Trg :  who were born not of blood nor of the will of the flesh nor of the will of man but of god\n",
      "Pred:  who doesn of blood nor of the flesh of the flesh of man but of god were revealed\n",
      "\n",
      "Validation perplexity: 9.297739\n",
      "Epoch 7\n",
      "Epoch Step: 100 Loss: 52.983356 Tokens per Sec: 7673.883814\n",
      "Epoch Step: 200 Loss: 29.306362 Tokens per Sec: 8096.776862\n",
      "Epoch Step: 300 Loss: 70.794510 Tokens per Sec: 8300.310079\n",
      "Epoch Step: 400 Loss: 33.853214 Tokens per Sec: 7553.386153\n",
      "Epoch Step: 500 Loss: 77.465248 Tokens per Sec: 7685.825404\n",
      "\n",
      "Example #1\n",
      "Src :  yea he putteth his life in his hand and smiteth the philistine and jehovah worketh great salvation for all israel thou hast seen and dost rejoice and why dost thou sin against innocent blood to put david to death for nought\n",
      "Trg :  for he put his life in his hand and struck the philistine and yahweh worked great victory for all israel you saw it and did rejoice why then will you sin against innocent blood to kill david without cause\n",
      "Pred:  he put his life in his hand and struck the philistine and yahweh gave great salvation for all israel you have seen and do so that you have mercy to kill you to death to death to death\n",
      "\n",
      "Example #2\n",
      "Src :  take therefore from him the talent and give to him having the ten talents\n",
      "Trg :  take away therefore the talent from him and give it to him who has the ten talents\n",
      "Pred:  take therefore from him the <unk> and gave him the <unk> of them\n",
      "\n",
      "Example #3\n",
      "Src :  who not of blood nor of will of flesh nor of will of man but of god were begotten\n",
      "Trg :  who were born not of blood nor of the will of the flesh nor of the will of man but of god\n",
      "Pred:  who doesn of the blood nor of the flesh of flesh neither of the desire of man but of god were born\n",
      "\n",
      "Validation perplexity: 8.891163\n",
      "Epoch 8\n",
      "Epoch Step: 100 Loss: 43.881142 Tokens per Sec: 9433.918951\n",
      "Epoch Step: 200 Loss: 40.243885 Tokens per Sec: 7832.983569\n",
      "Epoch Step: 300 Loss: 41.721905 Tokens per Sec: 7525.459903\n",
      "Epoch Step: 400 Loss: 69.000542 Tokens per Sec: 7730.362805\n",
      "Epoch Step: 500 Loss: 38.707249 Tokens per Sec: 7575.957464\n",
      "\n",
      "Example #1\n",
      "Src :  yea he putteth his life in his hand and smiteth the philistine and jehovah worketh great salvation for all israel thou hast seen and dost rejoice and why dost thou sin against innocent blood to put david to death for nought\n",
      "Trg :  for he put his life in his hand and struck the philistine and yahweh worked great victory for all israel you saw it and did rejoice why then will you sin against innocent blood to kill david without cause\n",
      "Pred:  he put his life in his hand and struck the philistine and yahweh repented great salvation for all israel you have seen and do you see why should sin against itself to give david to give david to death to death\n",
      "\n",
      "Example #2\n",
      "Src :  take therefore from him the talent and give to him having the ten talents\n",
      "Trg :  take away therefore the talent from him and give it to him who has the ten talents\n",
      "Pred:  take therefore from him the talent and gave him the <unk> of them\n",
      "\n",
      "Example #3\n",
      "Src :  who not of blood nor of will of flesh nor of will of man but of god were begotten\n",
      "Trg :  who were born not of blood nor of the will of the flesh nor of the will of man but of god\n",
      "Pred:  who doesn not of blood nor of the flesh of man but of god were born\n",
      "\n",
      "Validation perplexity: 9.080273\n",
      "Epoch 9\n",
      "Epoch Step: 100 Loss: 34.868980 Tokens per Sec: 7128.117756\n",
      "Epoch Step: 200 Loss: 32.533131 Tokens per Sec: 7773.929341\n",
      "Epoch Step: 300 Loss: 34.528816 Tokens per Sec: 9220.407745\n",
      "Epoch Step: 400 Loss: 45.958057 Tokens per Sec: 8241.041203\n",
      "Epoch Step: 500 Loss: 34.505573 Tokens per Sec: 7432.176316\n",
      "\n",
      "Example #1\n",
      "Src :  yea he putteth his life in his hand and smiteth the philistine and jehovah worketh great salvation for all israel thou hast seen and dost rejoice and why dost thou sin against innocent blood to put david to death for nought\n",
      "Trg :  for he put his life in his hand and struck the philistine and yahweh worked great victory for all israel you saw it and did rejoice why then will you sin against innocent blood to kill david without cause\n",
      "Pred:  he put his life in his hand and struck the philistine and yahweh repented great salvation for all israel you have seen and do so why do you sin against itself blood to death david to death\n",
      "\n",
      "Example #2\n",
      "Src :  take therefore from him the talent and give to him having the ten talents\n",
      "Trg :  take away therefore the talent from him and give it to him who has the ten talents\n",
      "Pred:  take from him the <unk> and gave him <unk> and ten hundred ten\n",
      "\n",
      "Example #3\n",
      "Src :  who not of blood nor of will of flesh nor of will of man but of god were begotten\n",
      "Trg :  who were born not of blood nor of the will of the flesh nor of the will of man but of god\n",
      "Pred:  who doesn of the shadow nor of the flesh of the flesh neither of the man of god but of god were born\n",
      "\n",
      "Validation perplexity: 8.217398\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EncoderDecoder(\n",
       "  (encoder): Encoder(\n",
       "    (rnn): GRU(256, 256, num_layers=3, batch_first=True, dropout=0.2, bidirectional=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (attention): BahdanauAttention(\n",
       "      (key_layer): Linear(in_features=512, out_features=256, bias=False)\n",
       "      (query_layer): Linear(in_features=256, out_features=256, bias=False)\n",
       "      (energy_layer): Linear(in_features=256, out_features=1, bias=False)\n",
       "    )\n",
       "    (rnn): GRU(768, 256, num_layers=3, batch_first=True, dropout=0.2)\n",
       "    (bridge): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (dropout_layer): Dropout(p=0.2, inplace=False)\n",
       "    (pre_output_layer): Linear(in_features=1024, out_features=256, bias=False)\n",
       "  )\n",
       "  (src_embed): Embedding(4306, 256)\n",
       "  (trg_embed): Embedding(4351, 256)\n",
       "  (generator): Generator(\n",
       "    (proj): Linear(in_features=256, out_features=4351, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = make_model(len(SRC.vocab), len(TRG.vocab),\n",
    "                   emb_size=256, hidden_size=256,\n",
    "                   num_layers=3, dropout=0.2)\n",
    "\n",
    "dev_perplexities = train(model,num_epochs=10, print_every=100)\n",
    "model.load_state_dict(torch.load('model_epoch_30'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_from_epoch(model, num_epochs=50, lr=0.0003, print_every=100, epoch_start=0):\n",
    "    \"\"\"Train a model on IWSLT\"\"\"\n",
    "    \n",
    "    if USE_CUDA:\n",
    "        model.cuda()\n",
    "\n",
    "    # optionally add label smoothing; see the Annotated Transformer\n",
    "    criterion = nn.NLLLoss(reduction=\"sum\", ignore_index=PAD_INDEX)\n",
    "    optim = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    dev_perplexities = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "      \n",
    "        print(\"Epoch\", epoch+epoch_start)\n",
    "        torch.save(model.state_dict(), 'model_epoch_' + str(epoch+epoch_start))\n",
    "\n",
    "        model.train()\n",
    "        train_perplexity = run_epoch((rebatch(PAD_INDEX, b) for b in train_iter), \n",
    "                                     model,\n",
    "                                     SimpleLossCompute(model.generator, criterion, optim),\n",
    "                                     print_every=print_every)\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            print_examples((rebatch(PAD_INDEX, x) for x in valid_iter), \n",
    "                           model, n=3, src_vocab=SRC.vocab, trg_vocab=TRG.vocab)        \n",
    "\n",
    "            dev_perplexity = run_epoch((rebatch(PAD_INDEX, b) for b in valid_iter), \n",
    "                                       model, \n",
    "                                       SimpleLossCompute(model.generator, criterion, None))\n",
    "            print(\"Validation perplexity: %f\" % dev_perplexity)\n",
    "            dev_perplexities.append(dev_perplexity)\n",
    "    torch.save(model.state_dict(), 'model_Final')\n",
    "\n",
    "    return dev_perplexities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10\n",
      "Epoch Step: 100 Loss: 35.821331 Tokens per Sec: 7009.113167\n",
      "Epoch Step: 200 Loss: 25.276556 Tokens per Sec: 6594.874926\n",
      "Epoch Step: 300 Loss: 26.259104 Tokens per Sec: 6542.735970\n",
      "Epoch Step: 400 Loss: 52.920311 Tokens per Sec: 6356.165963\n",
      "Epoch Step: 500 Loss: 35.956310 Tokens per Sec: 6603.157095\n",
      "\n",
      "Example #1\n",
      "Src :  yea he putteth his life in his hand and smiteth the philistine and jehovah worketh great salvation for all israel thou hast seen and dost rejoice and why dost thou sin against innocent blood to put david to death for nought\n",
      "Trg :  for he put his life in his hand and struck the philistine and yahweh worked great victory for all israel you saw it and did rejoice why then will you sin against innocent blood to kill david without cause\n",
      "Pred:  he put his life in his hand and struck the philistine and yahweh gave great salvation for all israel you have seen and do you why do you sin against innocent blood to death to death\n",
      "\n",
      "Example #2\n",
      "Src :  take therefore from him the talent and give to him having the ten talents\n",
      "Trg :  take away therefore the talent from him and give it to him who has the ten talents\n",
      "Pred:  therefore take from him the five and gave him ten ten talents\n",
      "\n",
      "Example #3\n",
      "Src :  who not of blood nor of will of flesh nor of will of man but of god were begotten\n",
      "Trg :  who were born not of blood nor of the will of the flesh nor of the will of man but of god\n",
      "Pred:  who doesn of the thirsty neither of the flesh of the flesh neither of the man of man but of god were born\n",
      "\n",
      "Validation perplexity: 8.112408\n",
      "Epoch 11\n",
      "Epoch Step: 100 Loss: 12.479086 Tokens per Sec: 6753.042268\n",
      "Epoch Step: 200 Loss: 39.158405 Tokens per Sec: 7217.443906\n",
      "Epoch Step: 300 Loss: 21.463718 Tokens per Sec: 6959.663887\n",
      "Epoch Step: 400 Loss: 12.803227 Tokens per Sec: 6832.010803\n",
      "Epoch Step: 500 Loss: 23.026382 Tokens per Sec: 7005.446048\n",
      "\n",
      "Example #1\n",
      "Src :  yea he putteth his life in his hand and smiteth the philistine and jehovah worketh great salvation for all israel thou hast seen and dost rejoice and why dost thou sin against innocent blood to put david to death for nought\n",
      "Trg :  for he put his life in his hand and struck the philistine and yahweh worked great victory for all israel you saw it and did rejoice why then will you sin against innocent blood to kill david without cause\n",
      "Pred:  he put his life in his hand and struck the philistine and yahweh repented great salvation for all israel you have seen and do you sin against itself blood to kill david\n",
      "\n",
      "Example #2\n",
      "Src :  take therefore from him the talent and give to him having the ten talents\n",
      "Trg :  take away therefore the talent from him and give it to him who has the ten talents\n",
      "Pred:  take him from him the one and gave him <unk> and ten ten talents\n",
      "\n",
      "Example #3\n",
      "Src :  who not of blood nor of will of flesh nor of will of man but of god were begotten\n",
      "Trg :  who were born not of blood nor of the will of the flesh nor of the will of man but of god\n",
      "Pred:  who doesn of no neither eat of the flesh of the flesh of man but of god were born\n",
      "\n",
      "Validation perplexity: 8.149577\n",
      "Epoch 12\n",
      "Epoch Step: 100 Loss: 38.193745 Tokens per Sec: 7381.799294\n",
      "Epoch Step: 200 Loss: 51.131779 Tokens per Sec: 6993.098974\n",
      "Epoch Step: 300 Loss: 35.640949 Tokens per Sec: 6743.560443\n",
      "Epoch Step: 400 Loss: 37.149708 Tokens per Sec: 7313.148779\n",
      "Epoch Step: 500 Loss: 69.356972 Tokens per Sec: 7678.276516\n",
      "\n",
      "Example #1\n",
      "Src :  yea he putteth his life in his hand and smiteth the philistine and jehovah worketh great salvation for all israel thou hast seen and dost rejoice and why dost thou sin against innocent blood to put david to death for nought\n",
      "Trg :  for he put his life in his hand and struck the philistine and yahweh worked great victory for all israel you saw it and did rejoice why then will you sin against innocent blood to kill david without cause\n",
      "Pred:  he put his life in his hand and struck the philistine and yahweh repented great salvation for all israel you have seen and do you and why do you sin against innocent blood to death david to be put to death\n",
      "\n",
      "Example #2\n",
      "Src :  take therefore from him the talent and give to him having the ten talents\n",
      "Trg :  take away therefore the talent from him and give it to him who has the ten talents\n",
      "Pred:  take therefore from him the talent and gave him <unk> and ten ten talents\n",
      "\n",
      "Example #3\n",
      "Src :  who not of blood nor of will of flesh nor of will of man but of god were begotten\n",
      "Trg :  who were born not of blood nor of the will of the flesh nor of the will of man but of god\n",
      "Pred:  who doesn of no thirsty of the shadow of flesh neither of the flesh of man but of god were born\n",
      "\n",
      "Validation perplexity: 8.029802\n",
      "Epoch 13\n",
      "Epoch Step: 100 Loss: 29.708570 Tokens per Sec: 7816.089048\n",
      "Epoch Step: 200 Loss: 33.071392 Tokens per Sec: 7309.695150\n",
      "Epoch Step: 300 Loss: 29.789454 Tokens per Sec: 7083.709444\n",
      "Epoch Step: 400 Loss: 47.461514 Tokens per Sec: 7137.089710\n",
      "Epoch Step: 500 Loss: 23.491543 Tokens per Sec: 7630.424640\n",
      "\n",
      "Example #1\n",
      "Src :  yea he putteth his life in his hand and smiteth the philistine and jehovah worketh great salvation for all israel thou hast seen and dost rejoice and why dost thou sin against innocent blood to put david to death for nought\n",
      "Trg :  for he put his life in his hand and struck the philistine and yahweh worked great victory for all israel you saw it and did rejoice why then will you sin against innocent blood to kill david without cause\n",
      "Pred:  he put his life in his hand and struck the philistine and yahweh repented great salvation for all israel you have seen and do you see why should sin sin to kill jacob to death to death\n",
      "\n",
      "Example #2\n",
      "Src :  take therefore from him the talent and give to him having the ten talents\n",
      "Trg :  take away therefore the talent from him and give it to him who has the ten talents\n",
      "Pred:  take therefore from him the one and gave him <unk> and ten ten talents\n",
      "\n",
      "Example #3\n",
      "Src :  who not of blood nor of will of flesh nor of will of man but of god were begotten\n",
      "Trg :  who were born not of blood nor of the will of the flesh nor of the will of man but of god\n",
      "Pred:  who doesn of the thirsty neither of the flesh of flesh neither of the flesh of man but of god were born\n",
      "\n",
      "Validation perplexity: 7.950835\n",
      "Epoch 14\n",
      "Epoch Step: 100 Loss: 49.853436 Tokens per Sec: 6898.264807\n",
      "Epoch Step: 200 Loss: 28.415089 Tokens per Sec: 7207.732676\n",
      "Epoch Step: 300 Loss: 18.442547 Tokens per Sec: 7544.731775\n",
      "Epoch Step: 400 Loss: 45.084858 Tokens per Sec: 8009.650516\n",
      "Epoch Step: 500 Loss: 20.952112 Tokens per Sec: 7317.625222\n",
      "\n",
      "Example #1\n",
      "Src :  yea he putteth his life in his hand and smiteth the philistine and jehovah worketh great salvation for all israel thou hast seen and dost rejoice and why dost thou sin against innocent blood to put david to death for nought\n",
      "Trg :  for he put his life in his hand and struck the philistine and yahweh worked great victory for all israel you saw it and did rejoice why then will you sin against innocent blood to kill david without cause\n",
      "Pred:  he put his life in his hand and struck the philistine and yahweh worked great victory for all israel you saw and do you why do you sin against innocent blood to kill david\n",
      "\n",
      "Example #2\n",
      "Src :  take therefore from him the talent and give to him having the ten talents\n",
      "Trg :  take away therefore the talent from him and give it to him who has the ten talents\n",
      "Pred:  take therefore from him the one and gave him <unk> and the ten talents\n",
      "\n",
      "Example #3\n",
      "Src :  who not of blood nor of will of flesh nor of will of man but of god were begotten\n",
      "Trg :  who were born not of blood nor of the will of the flesh nor of the will of man but of god\n",
      "Pred:  who doesn of no thirsty nor of the flesh of the flesh neither of god will be of god but god\n",
      "\n",
      "Validation perplexity: 8.048833\n",
      "Epoch 15\n",
      "Epoch Step: 100 Loss: 18.061214 Tokens per Sec: 7033.086877\n",
      "Epoch Step: 200 Loss: 39.269058 Tokens per Sec: 7216.054165\n",
      "Epoch Step: 300 Loss: 26.548517 Tokens per Sec: 7466.474188\n",
      "Epoch Step: 400 Loss: 44.112488 Tokens per Sec: 7590.214029\n",
      "Epoch Step: 500 Loss: 13.532623 Tokens per Sec: 7611.416684\n",
      "\n",
      "Example #1\n",
      "Src :  yea he putteth his life in his hand and smiteth the philistine and jehovah worketh great salvation for all israel thou hast seen and dost rejoice and why dost thou sin against innocent blood to put david to death for nought\n",
      "Trg :  for he put his life in his hand and struck the philistine and yahweh worked great victory for all israel you saw it and did rejoice why then will you sin against innocent blood to kill david without cause\n",
      "Pred:  he put his life in his hand and struck the philistine and yahweh worked great salvation for all israel you have seen and do you why do you sin against innocent blood to death to death\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example #2\n",
      "Src :  take therefore from him the talent and give to him having the ten talents\n",
      "Trg :  take away therefore the talent from him and give it to him who has the ten talents\n",
      "Pred:  take therefore from him the one and gave him <unk> and ten ten talents\n",
      "\n",
      "Example #3\n",
      "Src :  who not of blood nor of will of flesh nor of will of man but of god were begotten\n",
      "Trg :  who were born not of blood nor of the will of the flesh nor of the will of man but of god\n",
      "Pred:  who doesn of the thirsty nor of the flesh of the flesh neither of the flesh of man but of god are born\n",
      "\n",
      "Validation perplexity: 8.038753\n",
      "Epoch 16\n",
      "Epoch Step: 100 Loss: 14.420735 Tokens per Sec: 7370.892460\n",
      "Epoch Step: 200 Loss: 19.995144 Tokens per Sec: 7054.755297\n",
      "Epoch Step: 300 Loss: 44.234028 Tokens per Sec: 7409.444975\n",
      "Epoch Step: 400 Loss: 25.044319 Tokens per Sec: 7572.283551\n",
      "Epoch Step: 500 Loss: 45.787323 Tokens per Sec: 8184.837924\n",
      "\n",
      "Example #1\n",
      "Src :  yea he putteth his life in his hand and smiteth the philistine and jehovah worketh great salvation for all israel thou hast seen and dost rejoice and why dost thou sin against innocent blood to put david to death for nought\n",
      "Trg :  for he put his life in his hand and struck the philistine and yahweh worked great victory for all israel you saw it and did rejoice why then will you sin against innocent blood to kill david without cause\n",
      "Pred:  he put his life in his hand and struck the philistine and yahweh worked great salvation for all israel you have seen and do you why do you sin against innocent blood to death to death\n",
      "\n",
      "Example #2\n",
      "Src :  take therefore from him the talent and give to him having the ten talents\n",
      "Trg :  take away therefore the talent from him and give it to him who has the ten talents\n",
      "Pred:  take therefore from him the one and gave him <unk> him and ten ten talents\n",
      "\n",
      "Example #3\n",
      "Src :  who not of blood nor of will of flesh nor of will of man but of god were begotten\n",
      "Trg :  who were born not of blood nor of the will of the flesh nor of the will of man but of god\n",
      "Pred:  who doesn of the thirsty nor of the flesh of flesh or of the <unk> of man but of god were born\n",
      "\n",
      "Validation perplexity: 8.205517\n",
      "Epoch 17\n",
      "Epoch Step: 100 Loss: 36.166710 Tokens per Sec: 6782.400825\n",
      "Epoch Step: 200 Loss: 24.869833 Tokens per Sec: 7038.103879\n",
      "Epoch Step: 300 Loss: 33.297230 Tokens per Sec: 7429.536998\n",
      "Epoch Step: 400 Loss: 29.520607 Tokens per Sec: 7270.601445\n",
      "Epoch Step: 500 Loss: 22.359341 Tokens per Sec: 6888.023904\n",
      "\n",
      "Example #1\n",
      "Src :  yea he putteth his life in his hand and smiteth the philistine and jehovah worketh great salvation for all israel thou hast seen and dost rejoice and why dost thou sin against innocent blood to put david to death for nought\n",
      "Trg :  for he put his life in his hand and struck the philistine and yahweh worked great victory for all israel you saw it and did rejoice why then will you sin against innocent blood to kill david without cause\n",
      "Pred:  he put his life in his hand and struck the philistine and yahweh worked great salvation for all israel you have seen and do you why do you sin against innocent blood to kill david to nothing to nothing to nothing\n",
      "\n",
      "Example #2\n",
      "Src :  take therefore from him the talent and give to him having the ten talents\n",
      "Trg :  take away therefore the talent from him and give it to him who has the ten talents\n",
      "Pred:  take therefore from him the one and gave him the <unk> of them\n",
      "\n",
      "Example #3\n",
      "Src :  who not of blood nor of will of flesh nor of will of man but of god were begotten\n",
      "Trg :  who were born not of blood nor of the will of the flesh nor of the will of man but of god\n",
      "Pred:  who doesn of the <unk> nor of the flesh of flesh neither of the flesh of man but of god were <unk>\n",
      "\n",
      "Validation perplexity: 8.837982\n",
      "Epoch 18\n",
      "Epoch Step: 100 Loss: 35.354488 Tokens per Sec: 7413.544108\n",
      "Epoch Step: 200 Loss: 28.286678 Tokens per Sec: 6886.935330\n",
      "Epoch Step: 300 Loss: 25.666166 Tokens per Sec: 7078.520664\n",
      "Epoch Step: 400 Loss: 39.015507 Tokens per Sec: 6808.761260\n",
      "Epoch Step: 500 Loss: 30.334219 Tokens per Sec: 6930.045188\n",
      "\n",
      "Example #1\n",
      "Src :  yea he putteth his life in his hand and smiteth the philistine and jehovah worketh great salvation for all israel thou hast seen and dost rejoice and why dost thou sin against innocent blood to put david to death for nought\n",
      "Trg :  for he put his life in his hand and struck the philistine and yahweh worked great victory for all israel you saw it and did rejoice why then will you sin against innocent blood to kill david without cause\n",
      "Pred:  he put his life in his hand and struck the philistine and yahweh worked great salvation for all israel you have seen and do you why do you sin against itself to give david to death\n",
      "\n",
      "Example #2\n",
      "Src :  take therefore from him the talent and give to him having the ten talents\n",
      "Trg :  take away therefore the talent from him and give it to him who has the ten talents\n",
      "Pred:  take therefore from him the one and gave him one of them and ten the ten talents\n",
      "\n",
      "Example #3\n",
      "Src :  who not of blood nor of will of flesh nor of will of man but of god were begotten\n",
      "Trg :  who were born not of blood nor of the will of the flesh nor of the will of man but of god\n",
      "Pred:  who doesn of the fruits nor of the flesh of flesh or of the flesh of man but of god are abraham\n",
      "\n",
      "Validation perplexity: 8.280781\n",
      "Epoch 19\n",
      "Epoch Step: 100 Loss: 23.009306 Tokens per Sec: 6916.186829\n",
      "Epoch Step: 200 Loss: 22.152275 Tokens per Sec: 6694.875112\n",
      "Epoch Step: 300 Loss: 29.867640 Tokens per Sec: 6965.805117\n",
      "Epoch Step: 400 Loss: 37.310154 Tokens per Sec: 7234.372352\n",
      "Epoch Step: 500 Loss: 29.152431 Tokens per Sec: 7506.263573\n",
      "\n",
      "Example #1\n",
      "Src :  yea he putteth his life in his hand and smiteth the philistine and jehovah worketh great salvation for all israel thou hast seen and dost rejoice and why dost thou sin against innocent blood to put david to death for nought\n",
      "Trg :  for he put his life in his hand and struck the philistine and yahweh worked great victory for all israel you saw it and did rejoice why then will you sin against innocent blood to kill david without cause\n",
      "Pred:  he put his life in his hand and struck the philistine and yahweh worked great victory for all israel you have seen and do you and why do you sin against innocent blood to kill david to commit him\n",
      "\n",
      "Example #2\n",
      "Src :  take therefore from him the talent and give to him having the ten talents\n",
      "Trg :  take away therefore the talent from him and give it to him who has the ten talents\n",
      "Pred:  take therefore from him the one and gave him the mina talents\n",
      "\n",
      "Example #3\n",
      "Src :  who not of blood nor of will of flesh nor of will of man but of god were begotten\n",
      "Trg :  who were born not of blood nor of the will of the flesh nor of the will of man but of god\n",
      "Pred:  who doesn not of blood nor of the flesh of flesh or of the flesh of man but of god were born\n",
      "\n",
      "Validation perplexity: 8.546278\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EncoderDecoder(\n",
       "  (encoder): Encoder(\n",
       "    (rnn): GRU(256, 256, num_layers=3, batch_first=True, dropout=0.2, bidirectional=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (attention): BahdanauAttention(\n",
       "      (key_layer): Linear(in_features=512, out_features=256, bias=False)\n",
       "      (query_layer): Linear(in_features=256, out_features=256, bias=False)\n",
       "      (energy_layer): Linear(in_features=256, out_features=1, bias=False)\n",
       "    )\n",
       "    (rnn): GRU(768, 256, num_layers=3, batch_first=True, dropout=0.2)\n",
       "    (bridge): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (dropout_layer): Dropout(p=0.2, inplace=False)\n",
       "    (pre_output_layer): Linear(in_features=1024, out_features=256, bias=False)\n",
       "  )\n",
       "  (src_embed): Embedding(4306, 256)\n",
       "  (trg_embed): Embedding(4351, 256)\n",
       "  (generator): Generator(\n",
       "    (proj): Linear(in_features=256, out_features=4351, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('model_epoch_9'))\n",
    "dev_perplexities = train_from_epoch(model,num_epochs=10, print_every=100, epoch_start=10)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_perplexities = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation perplexity epoch 0 : 4411.843900\n",
      "Validation perplexity epoch 1 : 61.483501\n",
      "Validation perplexity epoch 2 : 28.813935\n",
      "Validation perplexity epoch 3 : 17.245197\n",
      "Validation perplexity epoch 4 : 13.348745\n",
      "Validation perplexity epoch 5 : 11.266227\n",
      "Validation perplexity epoch 6 : 11.710562\n",
      "Validation perplexity epoch 7 : 9.297739\n",
      "Validation perplexity epoch 8 : 8.891163\n",
      "Validation perplexity epoch 9 : 9.080273\n",
      "Validation perplexity epoch 10 : 9.080273\n",
      "Validation perplexity epoch 11 : 8.112408\n",
      "Validation perplexity epoch 12 : 8.149577\n",
      "Validation perplexity epoch 13 : 8.029802\n",
      "Validation perplexity epoch 14 : 7.950835\n",
      "Validation perplexity epoch 15 : 8.048833\n",
      "Validation perplexity epoch 16 : 8.038753\n",
      "Validation perplexity epoch 17 : 8.205517\n",
      "Validation perplexity epoch 18 : 8.837982\n"
     ]
    }
   ],
   "source": [
    "dev_perplexities = []\n",
    "criterion = nn.NLLLoss(reduction=\"sum\", ignore_index=PAD_INDEX)\n",
    "for i in range(0,19) :\n",
    "    model.load_state_dict(torch.load('model_epoch_' + str(i)))\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():       \n",
    "\n",
    "        dev_perplexity = run_epoch((rebatch(PAD_INDEX, b) for b in valid_iter), \n",
    "                                   model, \n",
    "                                   SimpleLossCompute(model.generator, criterion, None),print_every=100)\n",
    "        print(\"Validation perplexity epoch \" + str(i) + \" : %f\" % dev_perplexity)\n",
    "        dev_perplexities.append(dev_perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_perplexity(dev_perplexities[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncoderDecoder(\n",
       "  (encoder): Encoder(\n",
       "    (rnn): GRU(256, 256, num_layers=3, batch_first=True, dropout=0.2, bidirectional=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (attention): BahdanauAttention(\n",
       "      (key_layer): Linear(in_features=512, out_features=256, bias=False)\n",
       "      (query_layer): Linear(in_features=256, out_features=256, bias=False)\n",
       "      (energy_layer): Linear(in_features=256, out_features=1, bias=False)\n",
       "    )\n",
       "    (rnn): GRU(768, 256, num_layers=3, batch_first=True, dropout=0.2)\n",
       "    (bridge): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (dropout_layer): Dropout(p=0.2, inplace=False)\n",
       "    (pre_output_layer): Linear(in_features=1024, out_features=256, bias=False)\n",
       "  )\n",
       "  (src_embed): Embedding(4306, 256)\n",
       "  (trg_embed): Embedding(4351, 256)\n",
       "  (generator): Generator(\n",
       "    (proj): Linear(in_features=256, out_features=4351, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('model_epoch_14'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iter = data.Iterator(test_data, batch_size=1, train=False, sort=False, repeat=False, \n",
    "                           device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example #1\n",
      "Src :  hollow with boards thou dost make it as it hath been shewed thee in the mount so do they make it\n",
      "Trg :  hollow with <unk> shall you make it as it has been shown you on the mountain so shall they make it\n",
      "Pred:  will make it hollow with boards with boards as it is exalted you shall make you in the mountain so shall they make it\n",
      "\n",
      "Example #2\n",
      "Src :  and also have heard the groaning of the sons of israel whom the egyptians are causing to serve and remember my covenant\n",
      "Trg :  moreover have heard the groaning of the children of israel whom the egyptians keep in bondage and have remembered my covenant\n",
      "Pred:  also heard the pride of the children of israel whom the egyptians worship them and remember my covenant\n",
      "\n",
      "Example #3\n",
      "Src :  and he doth the evil thing in the eyes of jehovah according to all that jehoiakim hath done\n",
      "Trg :  he did that which was evil in the sight of yahweh according to all that jehoiakim had done\n",
      "Pred:  he did that which was evil in the sight of yahweh according to all that jehoiakim had done\n",
      "\n",
      "Example #4\n",
      "Src :  and take me up doth the spirit and bringeth me in unto the inner court and lo the honour of jehovah hath filled the house\n",
      "Trg :  the spirit took me up and brought me into the inner court and behold the glory of yahweh filled the house\n",
      "Pred:  then the spirit was taken up and brought me to the inner court behold the glory of yahweh filled the house\n",
      "\n",
      "Example #5\n",
      "Src :  and in any matter of wisdom and understanding that the king hath sought of them he findeth them ten hands above all the scribes the <unk> who are in all his kingdom\n",
      "Trg :  in every matter of wisdom and understanding concerning which the king inquired of them he found them ten times better than all the magicians and <unk> who were in all his realm\n",
      "Pred:  in any matter of wisdom and understanding that the king has sought them he found them ten hands on all the magicians the <unk> who were in all his kingdom\n",
      "\n",
      "Example #6\n",
      "Src :  drop as rain doth my <unk> flow as dew doth my sayings as <unk> on the tender grass and as showers on the herb\n",
      "Trg :  my doctrine shall drop as the rain my speech shall <unk> as the dew as the small rain on the tender grass as the showers on the herb\n",
      "Pred:  my <unk> will <unk> my <unk> like <unk> like <unk> like the grass as the grass as the grass\n",
      "\n",
      "Example #7\n",
      "Src :  and the battle is heavy on saul and those <unk> with the bow find him and he is wounded by those <unk>\n",
      "Trg :  the battle went sore against saul and the archers overtook him and he was distressed by reason of the archers\n",
      "Pred:  the battle was heavy on saul and those who <unk> the archers found him and he was slain by those who <unk>\n",
      "\n",
      "Example #8\n",
      "Src :  and he commanded the multitudes to sit down upon the ground\n",
      "Trg :  he commanded the multitude to sit down on the ground\n",
      "Pred:  he commanded the multitudes to sit down on the ground\n",
      "\n",
      "Example #9\n",
      "Src :  weak have been the two legs of the lame and <unk> in the mouth of fools\n",
      "Trg :  like the legs of the lame that hang loose so is parable in the mouth of fools\n",
      "Pred:  the two legs is made and the <unk> in the mouth of fools\n",
      "\n",
      "Example #10\n",
      "Src :  and they journey from <unk> and encamp in <unk>\n",
      "Trg :  they traveled from <unk> and encamped in <unk>\n",
      "Pred:  they traveled from <unk> and encamped in <unk>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_examples((rebatch(PAD_INDEX, x) for x in test_iter), \n",
    "               model, n=10, src_vocab=SRC.vocab, trg_vocab=TRG.vocab) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
